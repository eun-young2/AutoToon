# tagging_gpt_fastapi.py

from fastapi import FastAPI, APIRouter, HTTPException, Depends
from pydantic import BaseModel
from sqlalchemy.orm import Session
from transformers import ElectraTokenizer, ElectraForSequenceClassification
import torch
import pickle
from openai import OpenAI
import os
from dotenv import load_dotenv
from databases import Database
from sqlalchemy import Table, Column, Integer, String, MetaData, DateTime, select, text, func, ForeignKey
from datetime import date, datetime
from pathlib import Path

from backend.database import engine_sync, Base, get_db, ASYNC_DATABASE_URL

# âœ… .envì—ì„œ OpenAI í‚¤ ë¡œë“œ
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
client = OpenAI(api_key=OPENAI_API_KEY)

# âœ… ëª¨ë¸ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
MODEL_DIR = BASE_DIR / "koelectra-tagging-model"
LABEL_ENCODER_PATH = MODEL_DIR / "label_binarizer.pkl"

# â”€â”€â”€ ë°ì´í„°ë² ì´ìŠ¤(ë¹„ë™ê¸°) ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ASYNC_DATABASE_URL ì€ app/db.py ì—ì„œ f-string ìœ¼ë¡œ ìƒì„±ëœ URLì…ë‹ˆë‹¤.
database = Database(ASYNC_DATABASE_URL)
metadata = MetaData()

# âœ… tb_diary í…Œì´ë¸” ì •ì˜
tb_diary = Table(
    "tb_diary",
    metadata,
    Column("diary_num", Integer, primary_key=True),
    Column("user_id", String(100), ForeignKey("tb_user.user_id"), nullable=False),
    Column("content", String),
    Column("created_at", DateTime, default=datetime.utcnow)
)

# âœ… í…Œì´ë¸” ì •ì˜
tb_basic_question = Table(
    "tb_basic_question",
    metadata,
    Column("question_num", Integer, primary_key=True),
    Column("question", String),
    Column("created_at", DateTime, default=datetime.utcnow)
)

tb_user = Table(
    "tb_user",
    metadata,
    Column("user_id",       String(100),   primary_key=True),
    Column("user_name",     String(100),   nullable=False),
    Column("user_nick",     String(100),   nullable=False),
    Column("user_gender",   Integer,       nullable=False),
    Column("user_age_range",String(20),    nullable=True),
    Column("created_at",    DateTime,      nullable=False, default=datetime.utcnow),
    Column("credit",        Integer,       nullable=False, default=0),
    Column("correction_tape_item", Integer,nullable=False, default=0),
    Column("diary_item",    Integer,       nullable=False, default=0),
)

# â”€â”€â”€ Pydantic ëª¨ë¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class TaggingRequest(BaseModel):
    pass

class UserCheckRequest(BaseModel):
    user_id: str

class UserCheckResponse(BaseModel):
    user_id: str
    status: str        # "new_today" or "existing"
    joined_at: datetime | None

class GenerateQuestionRequest(BaseModel):
    user_id: str

# âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
if MODEL_DIR.is_dir():
    # ë¡œì»¬ ê²½ë¡œì—ì„œ ì§ì ‘ ë¶ˆëŸ¬ì˜¤ê¸°
    model = ElectraForSequenceClassification.from_pretrained(str(MODEL_DIR))
    tokenizer = ElectraTokenizer.from_pretrained(str(MODEL_DIR))
else:
    # (ì„ íƒ) Hugging Face Hub private repo ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (í† í°ì´ í•„ìš”í•¨)
    # model = ElectraForSequenceClassification.from_pretrained(
    #     "YOUR_HF_USERNAME/koelectra-tagging-model",
    #     use_auth_token=HF_TOKEN
    # )
    # tokenizer = ElectraTokenizer.from_pretrained(
    #     "YOUR_HF_USERNAME/koelectra-tagging-model",
    #     use_auth_token=HF_TOKEN
    # )
    raise FileNotFoundError(f"Cannot find local model directory: {MODEL_DIR}")

with open(LABEL_ENCODER_PATH, "rb") as f:
    mlb = pickle.load(f)

# â”€â”€â”€ 1) APIRouter ìƒì„± ë° ì—”ë“œí¬ì¸íŠ¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(
    prefix="/tagging",      # ëª¨ë“  ê²½ë¡œê°€ /tagging/** ë¡œ ì‹œì‘
    tags=["tagging"]
)

@router.get("/show-dbs")
async def show_databases():
    query = text("SHOW DATABASES;")
    rows = await database.fetch_all(query)
    return [row[0] for row in rows]

@router.on_event("startup")
async def startup():
    await database.connect()

@router.on_event("shutdown")
async def shutdown():
    await database.disconnect()

# âœ… íƒœê·¸ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_tags(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding="max_length", max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.sigmoid(outputs.logits)
        preds = (probs > 0.5).int().numpy()
        return mlb.inverse_transform(preds)[0]  # list of predicted tags

# âœ… GPT APIë¡œ ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜
def generate_custom_question(base_question, tags):
    tag_text = ", ".join(tags)
    print("ğŸ“Œ GPT í˜¸ì¶œ íƒœê·¸:", tag_text, flush=True)

    prompt = f"""
    ì•„ë˜ëŠ” ì‚¬ìš©ì ì¼ê¸°ì—ì„œ ê°ì§€ëœ ë¬¸ì²´/ë§íˆ¬/ê°ì • íƒœê·¸ì…ë‹ˆë‹¤: [{tag_text}]
    ì•„ë˜ ê¸°ë³¸ ì§ˆë¬¸ì„ ì´ ë¬¸ì²´ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í˜•í•´ ì£¼ì„¸ìš”.

    ê¸°ë³¸ ì§ˆë¬¸: {base_question}
    """

    # âœ… OpenAI ê°ì²´ ìƒì„± (í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜´)
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # âœ… ChatCompletion í˜¸ì¶œ (ì‹ ê·œ ë°©ì‹)
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ë¬¸ì²´ì— ë§ì¶° ì§ˆë¬¸ì„ ë¦¬ë””ìì¸í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )

    result = response.choices[0].message.content.strip()
    print("ğŸ“Œ GPT ì‘ë‹µ:", result, flush=True)
    return result

# âœ… ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
@router.post("/generate-question")
async def generate_question(request: GenerateQuestionRequest):

    query_diary = (select(tb_diary.c.content).where(tb_diary.c.user_id == request.user_id).order_by(tb_diary.c.created_at.desc()).limit(2))
    row_diary = await database.fetch_one(query_diary)

    if row_diary is None:
        raise HTTPException(status_code=404, detail="ìµœê·¼ ì¼ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤.")


    text = row_diary["content"]

    if len(text) < 100:
        raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
    
    tags = predict_tags(text)
    print("âœ… ì˜ˆì¸¡ íƒœê·¸:", tags)

    # âœ… DBì—ì„œ ê¸°ë³¸ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸° (ì˜ˆ: ì²« ë²ˆì§¸ ì§ˆë¬¸ë§Œ ì‚¬ìš©)
    query = select(tb_basic_question).order_by(func.rand()).limit(2)
    row = await database.fetch_one(query)

    if row is None:
        raise HTTPException(status_code=404, detail="ê¸°ë³¸ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

    base_question = row["question"]


    # âœ… GPTë¡œ ì§ˆë¬¸ ì¬ì‘ì„±
    new_question = generate_custom_question(base_question, tags)

    return {
        "predicted_tags": tags,
        "base_question": base_question,
        "customized_question": new_question
    }

# ì‹ ê·œ íšŒì›, ê¸°ì¡´ íšŒì› ë¶„ê¸° ë¡œì§
@router.post("/check-user-status", response_model=UserCheckResponse)
async def check_user_status(request: UserCheckRequest):

    user_id_to_check = request.user_id

    # 1) ìš°ì„ , í•´ë‹¹ user_idë¡œ ê°€ì…í•œ ë ˆì½”ë“œ(ê°€ì… ì‹œê°) ì¡°íšŒ
    #    SELECT user_id, created_at
    #    FROM tb_user
    #    WHERE user_id = :user_id_to_check
    query_find = (
        select(tb_user.c.user_id, tb_user.c.created_at)
        .where(tb_user.c.user_id == user_id_to_check)
        .limit(1)
    )

    row = await database.fetch_one(query_find)
    if row is None:
        # í•´ë‹¹ user_id ìì²´ê°€ DBì— ì—†ìœ¼ë©´ 404ë¡œ ì²˜ë¦¬
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì‚¬ìš©ìê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    joined_at: datetime = row["created_at"]

    # 2) joined_at ë‚ ì§œ ë¶€ë¶„ë§Œ â€œYYYY-MM-DDâ€ ë¡œ ë¹„êµ
    #    íŒŒì´ì¬ì—ì„œ today_date ê³„ì‚°
    today_date = date.today()

    #     func.date(tb_user.c.created_at) == today_date
    # ëŒ€ì‹ , ì´ë¯¸ joined_at ì„ íŒŒì´ì¬ datetimeìœ¼ë¡œ ë°›ì•„ ì™”ìœ¼ë¯€ë¡œ
    # joined_at.date() ì™€ ë¹„êµí•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.
    if joined_at.date() == today_date:
        # ì˜¤ëŠ˜ ê°€ì…í•œ íšŒì›ì´ë¯€ë¡œ â€œnew_todayâ€
        status = "new_today"
    else:
        # ì˜¤ëŠ˜ ì´ì „ì— ê°€ì…í•œ ê¸°ì¡´ íšŒì›
        status = "existing"

    return {
        "user_id": user_id_to_check,
        "status": status,
        "joined_at": joined_at
    }